{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition by Data Camp\n",
    "## Part 4 : Processing text transcribed from spoken language  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AudioSegment from Pydub\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# import the SpeechRecognition library\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert audio file to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to convert audio file to wav\n",
    "def convert_to_wav(filename):\n",
    "    \"\"\"Takes an audio file of non .wav format and converts to .wav\"\"\"\n",
    "    \n",
    "    folder = \"/\".join(filename.split(\"/\")[:-1])\n",
    "    # Import audio file\n",
    "    audio = AudioSegment.from_file(filename)\n",
    "\n",
    "    # Create new filename\n",
    "    new_filename = folder+\"/\"+ filename.split(\"/\")[-1].split(\".\")[0] + \".wav\"\n",
    "    \n",
    "    # Export file as .wav\n",
    "    audio.export(new_filename, format=\"wav\")\n",
    "    print(f\"Converting {filename} to {new_filename}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pydub_stats(filename):\n",
    "    \"\"\"Returns different audio attributes related to an audio file.\"\"\"\n",
    "    # Create AudioSegment instance\n",
    "    audio_segment = AudioSegment.from_file(filename)\n",
    "    \n",
    "    # Print audio attributes and return AudioSegment instance\n",
    "    print(f\"Channels: {audio_segment.channels}\")\n",
    "    print(f\"Sample width: {audio_segment.sample_width}\")\n",
    "    print(f\"Frame rate (sample rate): {audio_segment.frame_rate}\")\n",
    "    print(f\"Frame width: {audio_segment.frame_width}\")\n",
    "    print(f\"Length (ms): {len(audio_segment)}\")\n",
    "    return audio_segment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe Audio to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(filename):\n",
    "    \"\"\"Takes a .wav format audio file and transcribes it to text.\"\"\"\n",
    "    # Setup a recognizer instance\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Import the audio file and convert to audio data\n",
    "    audio_file = sr.AudioFile(filename)\n",
    "    with audio_file as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    # Return the transcribed text\n",
    "    return recognizer.recognize_google(audio_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ./data_part_4/ex4_call_1_stereo_formatted_mp3.mp3 to ./data_part_4/ex4_call_1_stereo_formatted_mp3.wav...\n",
      "Channels: 2\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 4\n",
      "Length (ms): 54888\n",
      "hey Daniel this is John I've recently bought a smartphone from you are 3 weeks ago and already having issues that one second grandma serial number it is for 177 I'm very displays how long do you reckon it's going to take me about an hour now right I'm just just really really really really just I've been trying to contact the ports and pass past 3-4 days now and have been put on hold Morgan and not really happy I can't get this issue fixed as fast as possible\n"
     ]
    }
   ],
   "source": [
    "# Convert mp3 file to wav\n",
    "convert_to_wav(\"./data_part_4/ex4_call_1_stereo_formatted_mp3.mp3\")\n",
    "\n",
    "# Check the stats of new file+\n",
    "call_1_audio_segment = show_pydub_stats(\"./data_part_4/ex4_call_1_stereo_formatted_mp3.wav\")\n",
    "\n",
    "\n",
    "# Split call_1 to mono\n",
    "call_1_split = call_1_audio_segment.split_to_mono()\n",
    "\n",
    "# Export channel 2 (the customer channel)\n",
    "call_1_split[1].export(\"./data_part_4/call_1_channel_2.wav\",\n",
    "                       format=\"wav\")\n",
    "\n",
    "\n",
    "# Transcribe the single channel\n",
    "print(transcribe_audio(\"./data_part_4/call_1_channel_2.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing sentiment of a phone call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello my name is Daniel thank you for calling acne Studios how can I best help you are hi Daniel my name is Sally I've recently purchased a smart phone from you guys and extremely happy with it but I just got to learn a little bit more about the message bank OK Google location but I'm finding it hard I got you on the corner of Edward and Elizabeth according to Google according to the maps but damn would you be able to help me in some way because I think I actually walk straight past your shop yeah sure thing I'll thank you Sally that's good to hear you're enjoying it let me let me find out where the nearest stories for you\n",
      "{'neg': 0.035, 'neu': 0.706, 'pos': 0.259, 'compound': 0.9844}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "try:\n",
    "    # Create SentimentIntensityAnalyzer instance\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "except Exception:\n",
    "    import nltk\n",
    "    nltk.download('vader_lexicon')\n",
    "    # Create SentimentIntensityAnalyzer instance\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "# Let's try it on one of our phone calls\n",
    "call_2_text = transcribe_audio(\"./data_part_4/ex4_call_2_stereo_native.wav\")\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(call_2_text)\n",
    "print(sid.polarity_scores(call_2_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis on formatted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh hi Daniel my name is belly I've recently purchased a smartphone from you guys and extremely happy with them I've just got an issue but I've just got to learn a little bit more about the message Frank I had Google the location but I'm finding it hard I don't you want the corner of Edward and Elizabeth according to Google according to the maps but damn would you be able to help me in some way because I think I actually walk straight past your shop\n",
      "{'neg': 0.071, 'neu': 0.836, 'pos': 0.092, 'compound': 0.443}\n"
     ]
    }
   ],
   "source": [
    "# Transcribe customer channel of call 2\n",
    "call_2_channel_2_text = transcribe_audio(\"./data_part_4/ex4_call_2_channel_2_formatted.wav\")\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(call_2_channel_2_text)\n",
    "print(sid.polarity_scores(call_2_channel_2_text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis on formatted text sentence by sentence  \n",
    "\n",
    "call_2_channel_2_text doesn't contain each sentences  \n",
    "call_2_channel_2_paid_api_text contains each sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh hi Daniel my name is belly I've recently purchased a smartphone from you guys and extremely happy with them I've just got an issue but I've just got to learn a little bit more about the message Frank I had Google the location but I'm finding it hard I don't you want the corner of Edward and Elizabeth according to Google according to the maps but damn would you be able to help me in some way because I think I actually walk straight past your shop\n",
      "{'neg': 0.071, 'neu': 0.836, 'pos': 0.092, 'compound': 0.443}\n"
     ]
    }
   ],
   "source": [
    "# Import sent_tokenize from nltk\n",
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "try:\n",
    "    sent_tokenize(call_2_channel_2_text)\n",
    "except Exception:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "# Split call 2 channel 2 into sentences and score each\n",
    "for sentence in sent_tokenize(call_2_channel_2_text):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello and welcome to acme studios.\n",
      "{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.4588}\n",
      "My name's Daniel.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "How can I best help you?\n",
      "{'neg': 0.0, 'neu': 0.303, 'pos': 0.697, 'compound': 0.7845}\n",
      "Hi Diane.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "This is paid on this call up to see the status of my, \n",
      "I'm proctor mortars at three weeks ago, \n",
      "and then service is terrible.\n",
      "{'neg': 0.114, 'neu': 0.886, 'pos': 0.0, 'compound': -0.4767}\n",
      "Okay, Peter, \n",
      "sorry to hear about that.\n",
      "{'neg': 0.159, 'neu': 0.61, 'pos': 0.232, 'compound': 0.1531}\n",
      "Hey, Peter, \n",
      "before we go on, do you mind just, uh, \n",
      "is there something going on with your microphone?\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "I can't quite hear you.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Is this any better?\n",
      "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "Yeah, that's much better.\n",
      "{'neg': 0.0, 'neu': 0.282, 'pos': 0.718, 'compound': 0.6249}\n",
      "And sorry, what was, \n",
      "what was it that you said when you first first started speaking?\n",
      "{'neg': 0.08, 'neu': 0.92, 'pos': 0.0, 'compound': -0.0772}\n",
      "So I ordered a product from you guys three weeks ago and, uh, it's, \n",
      "it's currently on July 1st and I haven't received a provocative, again, \n",
      "three weeks to a full four weeks down line.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "This service is terrible.\n",
      "{'neg': 0.508, 'neu': 0.492, 'pos': 0.0, 'compound': -0.4767}\n",
      "Okay.\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2263}\n",
      "Well, what's your order id?\n",
      "{'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.2732}\n",
      "I'll, uh, I'll start looking into that for you.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Six, nine, eight, seven five.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Okay.\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2263}\n",
      "Thank you.\n",
      "{'neg': 0.0, 'neu': 0.286, 'pos': 0.714, 'compound': 0.3612}\n"
     ]
    }
   ],
   "source": [
    "call_2_channel_2_paid_api_text = \"\"\"Hello and welcome to acme studios. \n",
    "My name's Daniel. How can I best help you? Hi Diane.\n",
    "This is paid on this call up to see the status of my, \n",
    "I'm proctor mortars at three weeks ago, \n",
    "and then service is terrible. Okay, Peter, \n",
    "sorry to hear about that. Hey, Peter, \n",
    "before we go on, do you mind just, uh, \n",
    "is there something going on with your microphone? \n",
    "I can't quite hear you. Is this any better? \n",
    "Yeah, that's much better. And sorry, what was, \n",
    "what was it that you said when you first first started speaking?\n",
    "So I ordered a product from you guys three weeks ago and, uh, it's, \n",
    "it's currently on July 1st and I haven't received a provocative, again, \n",
    "three weeks to a full four weeks down line. This service is terrible. Okay. \n",
    "Well, what's your order id? I'll, uh, I'll start looking into that for you. \n",
    "Six, nine, eight, seven five. Okay. Thank you.\"\"\"\n",
    "\n",
    "# Split call 2 channel 2 into sentences and score each\n",
    "for sentence in sent_tokenize(call_2_channel_2_paid_api_text):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named entity recognition in spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(doc) <class 'spacy.tokens.doc.Doc'>\n",
      "awful 0\n",
      "I 6\n",
      "Daniel 8\n",
      "my 15\n",
      "name 18\n",
      "is 23\n",
      "Ian 26\n",
      "and 30\n",
      "I 34\n",
      "'ve 35\n",
      "recently 39\n",
      "just 48\n",
      "purchased 53\n",
      "a 63\n",
      "smart 65\n",
      "phone 71\n",
      "from 77\n",
      "you 82\n",
      "and 86\n",
      "I 90\n",
      "'m 91\n",
      "very 94\n",
      "happy 99\n",
      "with 105\n",
      "the 110\n",
      "product 114\n",
      "I 122\n",
      "'d 123\n",
      "like 126\n",
      "to 131\n",
      "order 134\n",
      "another 140\n",
      "one 148\n",
      "for 152\n",
      "my 156\n",
      "friend 159\n",
      "who 166\n",
      "lives 170\n",
      "in 176\n",
      "Sydney 179\n",
      "and 186\n",
      "have 190\n",
      "it 195\n",
      "delivered 198\n",
      "I 208\n",
      "'m 209\n",
      "pretty 212\n",
      "sure 219\n",
      "it 224\n",
      "'s 226\n",
      "model 229\n",
      "315 235\n",
      "I 239\n",
      "can 241\n",
      "check 245\n",
      "that 251\n",
      "for 256\n",
      "you 260\n",
      "and 264\n",
      "I 268\n",
      "'ll 269\n",
      "give 273\n",
      "you 278\n",
      "my 282\n",
      "details 285\n",
      "and 293\n",
      "if 297\n",
      "you 300\n",
      "'d 303\n",
      "like 306\n",
      "to 311\n",
      "take 314\n",
      "my 319\n",
      "details 322\n",
      "and 330\n",
      "I 334\n",
      "will 336\n",
      "also 341\n",
      "give 346\n",
      "you 351\n",
      "the 355\n",
      "address 359\n",
      "thank 367\n",
      "you 373\n",
      "excellent 377\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Transcribe call 4 channel 2\n",
    "call_4_channel_2_text = transcribe_audio(\"./data_part_4/ex4_call_4_channel_2_formatted.wav\")\n",
    "\n",
    "# Create a spaCy language model instance\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc with call 4 channel 2 text\n",
    "doc = nlp(call_4_channel_2_text)\n",
    "\n",
    "# Check the type of doc\n",
    "print(\"type(doc) : \",type(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Token in doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awful 0\n",
      "I 6\n",
      "Daniel 8\n",
      "my 15\n",
      "name 18\n",
      "is 23\n",
      "Ian 26\n",
      "and 30\n",
      "I 34\n",
      "'ve 35\n",
      "recently 39\n",
      "just 48\n",
      "purchased 53\n",
      "a 63\n",
      "smart 65\n",
      "phone 71\n",
      "from 77\n",
      "you 82\n",
      "and 86\n",
      "I 90\n",
      "'m 91\n",
      "very 94\n",
      "happy 99\n",
      "with 105\n",
      "the 110\n",
      "product 114\n",
      "I 122\n",
      "'d 123\n",
      "like 126\n",
      "to 131\n",
      "order 134\n",
      "another 140\n",
      "one 148\n",
      "for 152\n",
      "my 156\n",
      "friend 159\n",
      "who 166\n",
      "lives 170\n",
      "in 176\n",
      "Sydney 179\n",
      "and 186\n",
      "have 190\n",
      "it 195\n",
      "delivered 198\n",
      "I 208\n",
      "'m 209\n",
      "pretty 212\n",
      "sure 219\n",
      "it 224\n",
      "'s 226\n",
      "model 229\n",
      "315 235\n",
      "I 239\n",
      "can 241\n",
      "check 245\n",
      "that 251\n",
      "for 256\n",
      "you 260\n",
      "and 264\n",
      "I 268\n",
      "'ll 269\n",
      "give 273\n",
      "you 278\n",
      "my 282\n",
      "details 285\n",
      "and 293\n",
      "if 297\n",
      "you 300\n",
      "'d 303\n",
      "like 306\n",
      "to 311\n",
      "take 314\n",
      "my 319\n",
      "details 322\n",
      "and 330\n",
      "I 334\n",
      "will 336\n",
      "also 341\n",
      "give 346\n",
      "you 351\n",
      "the 355\n",
      "address 359\n",
      "thank 367\n",
      "you 373\n",
      "excellent 377\n"
     ]
    }
   ],
   "source": [
    "# Show tokens in doc\n",
    "for token in doc:\n",
    "    print(token.text, token.idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show sentences in doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awful I Daniel my name is Ian\n",
      "and I've recently just purchased a smart phone from you\n",
      "and I'm very happy with the product I'd like to order another one for my friend who lives in Sydney and\n",
      "have it delivered\n",
      "I'm pretty sure\n",
      "it's model 315\n",
      "I can check that for you\n",
      "and I'll give you my details\n",
      "and if you'd like to take my details and I will also give you the address thank you excellent\n"
     ]
    }
   ],
   "source": [
    "# Show sentences in doc\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show named entities and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daniel PERSON\n",
      "Ian PERSON\n",
      "Sydney GPE\n",
      "315 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "# Show named entities and their labels\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a custom named entity in spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daniel PERSON\n",
      "Ian PERSON\n",
      "Sydney GPE\n",
      "315 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "# Import EntityRuler class\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Create EntityRuler instance\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "# Define pattern for new entity\n",
    "ruler.add_patterns([{\"label\": \"PRODUCT\", \"pattern\": \"smartphone\"}])\n",
    "\n",
    "# Update existing pipeline\n",
    "nlp.add_pipe(ruler, before=\"ner\")\n",
    "\n",
    "# Test new entity\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing audio files for text classification  \n",
    "\n",
    "#### We only have 2 provided audio files, one before, one after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ./data_part_4/post-purchase-audio-27.wav to .wav...\n",
      "Converting ./data_part_4/post-purchase-audio-27.wav to ./data_part_4/post-purchase-audio-27.wav...\n",
      "Converting ./data_part_4/pre-purchase-audio-25.wav to .wav...\n",
      "Converting ./data_part_4/pre-purchase-audio-25.wav to ./data_part_4/pre-purchase-audio-25.wav...\n"
     ]
    }
   ],
   "source": [
    "post_purchase=[\"./data_part_4/post-purchase-audio-27.wav\"]\n",
    "pre_purchase=[\"./data_part_4/pre-purchase-audio-25.wav\"]\n",
    "\n",
    "# Convert post purchase\n",
    "for file in post_purchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    convert_to_wav(file)\n",
    "\n",
    "# Convert pre purchase\n",
    "for file in pre_purchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    convert_to_wav(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribing phone call excerpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_list(folder):\n",
    "    # Create empty list\n",
    "    text_list = []\n",
    "    # Go through each file\n",
    "    for file in folder:\n",
    "        # Make sure the file is .wav\n",
    "        if file.endswith(\".wav\"):\n",
    "            print(f\"Transcribing file: {file}...\")\n",
    "\n",
    "            # Transcribe audio and append text to list\n",
    "            text_list.append(transcribe_audio(file))   \n",
    "    return text_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing file: ./data_part_4/post-purchase-audio-27.wav...\n",
      "Transcribing file: ./data_part_4/pre-purchase-audio-25.wav...\n",
      "I'm calling to talk about a package I got yesterday it's I got it but I need to I need some help with setting it up\n"
     ]
    }
   ],
   "source": [
    "# Transcribe post and pre purchase text\n",
    "post_purchase_text = create_text_list(post_purchase)\n",
    "pre_purchase_text  = create_text_list(pre_purchase)\n",
    "\n",
    "# Inspect the first transcription of post purchase\n",
    "print(post_purchase_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing transcribed phone call data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           label                                               text\n",
      "0  post_purchase  I'm calling to talk about a package I got yest...\n",
      "1  post_purchase  I'm calling to talk about a package I got yest...\n",
      "2  post_purchase  I'm calling to talk about a package I got yest...\n",
      "3  post_purchase  I'm calling to talk about a package I got yest...\n",
      "4  post_purchase  I'm calling to talk about a package I got yest...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_post_purchase_text = post_purchase_text * 100\n",
    "train_pre_purchase_text = pre_purchase_text * 100\n",
    "\n",
    "# Make dataframes with the text\n",
    "post_purchase_df = pd.DataFrame({\"label\": \"post_purchase\",\n",
    "                                 \"text\": train_post_purchase_text})\n",
    "pre_purchase_df = pd.DataFrame({\"label\": \"pre_purchase\",\n",
    "                                \"text\": train_pre_purchase_text})\n",
    "\n",
    "# Combine DataFrames\n",
    "df = pd.concat([post_purchase_df, pre_purchase_df])\n",
    "\n",
    "# Print the combined DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a spoken language text classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import text classification packages\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( df[\"text\"], df[\"label\"], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the text_classifier as an sklearn pipeline\n",
    "text_classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Fit the classifier pipeline on the training data\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is 100.00% accurate.\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and compare them to test labels\n",
    "predictions = text_classifier.predict(X_test)\n",
    "accuracy = 100 * np.mean(predictions == y_test)\n",
    "print(f\"The model is {accuracy:.2f}% accurate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
